{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "#from faker import Faker\n",
    "import re, json, logging , html, os\n",
    "from lib.config import connstr\n",
    "from lib.context import context\n",
    "from lib.utils import * \n",
    "from lib.picklist_recommender import picklist_recommender\n",
    "from lib.issue_parser import issue_parser\n",
    "from lib.issue_provider import issue_provider\n",
    "from lib.questionnaire_parser import questionnaire_parser\n",
    "from lib.dbupdate_parser import dbupdate_parser\n",
    "from lib.script_generator import script_generator \n",
    "from lib.db_parser import db_parser   \n",
    "from bs4 import BeautifulSoup    \n",
    "#from nltk.corpus import stopwords \n",
    "#sw=stopwords.words('english') \n",
    "ctx=context() \n",
    "ctx.logger.setLevel(logging.DEBUG)\n",
    "config = {}\n",
    "with open('config.json', 'r') as f: \n",
    "    config=json.loads(f.read())    \n",
    "ctx.config=config \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = '8433'\n",
    "with open ('cache/8433.html','r') as f:\n",
    "    txt=f.read()\n",
    "    txt=re.sub('&nbsp;', ' ', txt) \n",
    "    txt=re.sub('<p>\\s*</p>', ' ', txt)  \n",
    "    txt=re.sub('\\n\\s*\\n', '\\n', txt)\n",
    "    txt=re.sub('\\n{1,}', '\\n', txt)\n",
    "    \n",
    "print(txt)\n",
    "lines = re.split('(?:(\\n?.*>?\\d[\\d\\.a-z]+))\\s*', txt )\n",
    "metrics = zip(lines[1::2], lines[2::2])\n",
    "metrics = [f'{x} {y}' for x,y  in list(metrics)]\n",
    "metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_parser(ctx).parse('8787:8790')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE\n",
    "\n",
    "#### requirements > jira > sql > forms\n",
    "#### requirements/jira > sql > forms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# forms from sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = db_parser(ctx)\n",
    "df=parser.parse(question_group='4406')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code=script_generator(ctx).generate(df) \n",
    "print(code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jira Parse Entire Datacall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = issue_parser(ctx)     \n",
    "df=ip.parse('9600:9605' )  \n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sql from jira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=script_generator(ctx)\n",
    "code=gen.generate(df, code_template_path=f'{ctx.get_tempalte_dir()}aspx\\\\ig.sql')\n",
    "print(code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'Effective / Not Effective'\n",
    "picklist = string.split(' / ')\n",
    "print ( picklist ) \n",
    "pr = picklist_recommender(ctx, use_cache=False) \n",
    "pl=pr.recommend(picklist, generate_sql=False)\n",
    "pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aspx_generator():\n",
    "    def __init__(self, ctx):  \n",
    "        self.ctx=ctx \n",
    "    def generate(self, PK_FORM='2023-A-HVA', classname=None, where=None, commit=False, PageNameFilter='~', dest=None ):\n",
    "        parser=db_parser(ctx)\n",
    "        generator=script_generator(ctx)\n",
    "        sql= f\"\"\"\n",
    "            SELECT DISTINCT PK_FORM, PK_QuestionGroup, SectionNum, GroupName, ASPX\n",
    "            FROM vwQuestions  WHERE 1=1 AND PK_FORM='{PK_FORM}' \n",
    "            --AND {where}\n",
    "            ORDER BY PK_QuestionGroup ASC\n",
    "        \"\"\"\n",
    "        if classname == None: classname=PK_FORM.replace('-','_')\n",
    "        if where != None: sql=sql.replace('--AND', 'AND  ')\n",
    "        #print(sql)\n",
    "        df=sql_todf(sql, self.ctx.connstr)     \n",
    "        df['PNAME']=df['ASPX'].apply(lambda s: s.split('/')[len(s.split('/'))-1].replace('.aspx',''))\n",
    "        pages=df.to_dict(orient='records')    \n",
    "        src=ctx.get_tempalte_dir()\n",
    "        out=''\n",
    "        for p in pages:   \n",
    "            PageName = re.sub(PageNameFilter,'',f\"{classname}_{p['GroupName']}\")\n",
    "            for ext in ['.aspx','.aspx.designer.vb','.aspx.vb']:\n",
    "                with open(f'{src}{classname}{ext}', 'r', encoding='UTF-8', errors='ignore') as fr: \n",
    "                    txt = fr.read().encode(  'utf-8', errors='ignore' ).decode('utf-8')\n",
    "                    txt=txt.replace('{classname}',PageName) \n",
    "                    txt=txt.replace('{PK_key}',f\"{p['PK_QuestionGroup']}\")\n",
    "                    txt=txt.replace('{GroupName}',f\"{p['GroupName']}\")  \n",
    "                    if ext=='.aspx': \n",
    "                        parsed=parser.parse(question_group=p['PK_QuestionGroup'])\n",
    "                        code = generator.generate(parsed)\n",
    "                        txt=txt.replace(f'<!--controls-->',code) \n",
    "                    out=out+txt\n",
    "                path=f\"{dest}{p['PNAME']}{ext}\"\n",
    "                print(path)\n",
    "                if commit:  \n",
    "                    with open(path, 'w', encoding='UTF-8') as fw:\n",
    "                        fw.write(txt)\n",
    "        with open(fr\"{ctx.get_dest()}\\script.aspx\", 'w', encoding='UTF-8') as fw: \n",
    "            fw.write(out)\n",
    " \n",
    "dest=rf\"C:\\\\dev\\\\CyberScope\\\\CyberScopeBranch\\\\CSwebdev\\\\code\\\\CyberScope\\\\FismaForms\\\\2023\\\\\"  \n",
    "generate_pages(PK_FORM='2023-A-IG', where=' PK_QuestionGroup < 4461 ', commit=True, PageNameFilter='Function',dest=dest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a7c076192e1e16d3ee1a218e6831777c4d2e3a001a9a33f6decd6c7672cec63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
