{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re, json, os , logging , random, html, datetime, openpyxl\n",
    "from lib.config import connstr\n",
    "from lib.context import context\n",
    "from lib.utils import * \n",
    "from lib.picklist_recommender import picklist_recommender\n",
    "from lib.issue_provider import issue_provider\n",
    "from lib.questionnaire_parser import questionnaire_parser\n",
    "from lib.questionnaire_picklist_parser import questionnaire_picklist_parser\n",
    "from lib.script_generator import script_generator \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from bs4 import BeautifulSoup  \n",
    "ctx=context() \n",
    "ctx.logger.setLevel(logging.DEBUG)\n",
    "config = {}\n",
    "with open('config.json', 'r') as f: \n",
    "    config=json.loads(f.read())    \n",
    "ctx.config=config \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsql=\"\"\"\n",
    "\t\tIF ISNUMERIC(REPLACE(@M1,'.',''))<>1\n",
    "\t\tBEGIN\n",
    "\t\t\tSET @M1=0 \n",
    "\t\tEND\n",
    "\n",
    "\t\tIf NOT EXISTS(SELECT * FROM fsma_Answers WHERE FK_OrgSubmission=@PK_OrgSubmission AND FK_Question=22402)\n",
    "\t\tBEGIN\n",
    "\t\t\tINSERT INTO fsma_Answers (FK_Question, FK_OrgSubmission, DateModifed) VALUES (22402, @PK_OrgSubmission, @DateImported)\n",
    "\t\tEND\n",
    "\n",
    "\t\tINSERT INTO AuditLog (TableName, PK_PrimeKey, FieldName, FieldValue, Change_Date, UserID, PK_Agency, EditType) \n",
    "\t\tVALUES ('fsma_Answers', @PK_OrgSubmission, '22402', (SELECT TOP 1 Answer FROM fsma_Answers WHERE FK_OrgSubmission=@PK_OrgSubmission AND FK_Question=22402), @DateImported, @UserID, -1, 'U')\n",
    "\n",
    "\t\tUPDATE A SET Answer=@M1\n",
    "\t\tFROM fsma_Answers A\n",
    "\t\tINNER JOIN vw_OrgSubQuestions Q  ON Q.PK_Question=A.FK_Question AND Q.PK_OrgSubmission=@PK_OrgSubmission \n",
    "\t\tWHERE A.FK_OrgSubmission=@PK_OrgSubmission\n",
    "\t\tAND Q.PK_Question=22402\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "df=sql_todf(\"\"\"\n",
    "\tSELECT PK_Question, identifier_text\n",
    "\tFROM  vwOrgSubToComponent ORG \n",
    "\tINNER JOIN vw_OrgSubQuestions Q  ON ORG.PK_OrgSubmission =Q.PK_OrgSubmission \n",
    "\tLEFT JOIN fsma_Answers A ON ORG.PK_OrgSubmission=A.FK_OrgSubmission \n",
    "\tWHERE ORG.PK_OrgSubmission=26445 AND PK_QUESTION NOT IN (22401,22407)\n",
    "\"\"\", connstr)   \n",
    "df['m']=df['identifier_text'].apply( lambda s: f'@M{s.replace(\".\",\"_\")}' )\n",
    "df['tsql'] = [ tsql.replace('@M1',x[0] ).replace('22402',str(x[1]) ) for x in zip(df['m'], df['PK_Question'])]\n",
    "for s in df['tsql']:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, code = generate_code_from_db(ctx, 3273)\n",
    "df[21:25]\n",
    "#print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=script_generator(ctx)\n",
    "code=gen.generate(df[12:14])\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, code = generate_code_from_db(ctx, 3273)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hvasa_pages():\n",
    "    df=sql_todf(\"\"\"\n",
    "    SELECT DISTINCT PK_FORM, PK_QuestionGroup, SectionNum, ASPX\n",
    "    FROM vwQuestions\n",
    "    WHERE PK_FORM='2023-A-HVAENDPRO'\n",
    "    ORDER BY PK_QuestionGroup ASC\n",
    "    \"\"\", connstr)   \n",
    "    df['FASPX']=df['ASPX'].str.replace('HVA/2023/','')\n",
    "    df['PNAME']=df['FASPX'].str.replace('.aspx','') \n",
    "    pages=df.to_dict(orient='records') \n",
    "    #print(pages)\n",
    "    #return \n",
    "    base = r\"C:\\\\dev\\\\CyberScope\\\\CyberScopeBranch\\\\CSwebdev\\\\code\\\\CyberScope\\\\HVA\\\\2023\\\\\" \n",
    "    src = r'C:\\\\_som\\\\tmp\\\\'\n",
    "    for p in pages:  \n",
    "        for ext in ['.aspx','.aspx.designer.vb','.aspx.vb']:\n",
    "            with open(f'{src}2023_HVA_ENDPOINT_1{ext}', 'r', encoding='UTF-8') as fr: \n",
    "                txt = fr.read()\n",
    "                txt=txt.replace(f'11',f\"{p['SectionNum']}{p['SectionNum']}\")\n",
    "                txt=txt.replace(f\"INT_1\",f\"INT_{p['SectionNum']}\")\n",
    "                txt=txt.replace('{PK_key}',f\"{p['PK_QuestionGroup']}\")\n",
    "                #txt=txt.replace('ENDPOINT',f\"REMOTE\")\n",
    "                if ext=='.aspx': \n",
    "                    df, code = generate_code_from_db(ctx, qgroup=p['PK_QuestionGroup'])\n",
    "                    txt=txt.replace(f'<!--controls-->',code)\n",
    "                #print(txt)\n",
    "            with open(f\"{base}{p['PNAME']}{ext}\", 'w', encoding='UTF-8') as fw:\n",
    "                fw.write(txt)\n",
    "\n",
    "hvasa_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sql_todf(\"\"\"\n",
    "SELECT ORG.Acronym Agency, PK_CISA_CVE [CVE ID], RIGHT(PK_CISA_CVE, 4) [Count]\n",
    "FROM CVEs\n",
    "OUTER APPLY(\n",
    "\tSELECT PK_OrgSubmission, PK_Component, Acronym FROM vwOrgSubToComponent \n",
    "    WHERE PK_ReportingCycle=108 AND OrgSub_Description='ACTIVE' AND Acronym='USDA'\n",
    ") ORG\n",
    "\n",
    "\"\"\", connstr)  \n",
    "df.to_csv(r'C:\\Users\\timko\\Downloads\\usda.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 111.0.5563\n",
      "Get LATEST driver version for 111.0.5563\n",
      "There is no [win32] chromedriver for browser 111.0.5563 in cache\n",
      "Get LATEST driver version for 111.0.5563\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/111.0.5563.64/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\timko\\.wdm\\drivers\\chromedriver\\win32\\111.0.5563.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Key                                                                                   Summary\n",
      "0   CS-9496                               PQC Section 1 - remove limit on 'Budget Estimate' questions\n",
      "1   CS-9495                                           PQC Section 1- update required/optional columns\n",
      "2   CS-9494                                 PQC Section 1 - add 1 to row number on upload validations\n",
      "3   CS-9493                          Disable PQC - Section 1 Upload buttons when the form is 'Locked'\n",
      "4   CS-9484                          Create BOD 20-01 VDP Maintenance Upload to populate agency forms\n",
      "5   CS-9261                                       BOD 18-02 Annual 2023: Manage HVAs Agency Interface\n",
      "6   CS-8885                                                      create data request/response service\n",
      "7   CS-8678                       BOD 18-02 Annual HVA 2021: Update 'Manage HVA Interface' Audit Logs\n",
      "8   CS-8459                                                       Selenium Browser Automator Refactor\n",
      "9   CS-8279  Allow for multiple HVAs to be associated to a single HVA for BOD 18-02 Remediation Plans\n",
      "10  CS-8216                               EINSTEIN Global Audit History: Update Audit History Queries\n",
      "11  CS-8200                                     EINSTEIN Network Channels: Update ASN Grid Validation\n",
      "12  CS-8197                                             EINSTEIN BGP Info: Update ASN Grid Validation\n",
      "13  CS-8196                                       EINSTEIN BGP Info: Update BGP Route Grid Validation\n",
      "14  CS-8195                                EINSTEIN BGP Info: Update BGP Route File Upload Validation\n",
      "15  CS-8189                                    EINSTEIN Unannounced IP Space: IPv6 Address Validation\n",
      "16  CS-8185                        EINSTEIN Global Grid Update: Treat RETURN/ENTER key same as UPDATE\n",
      "17  CS-6999                                                                    Update US-CERT Dashlet\n"
     ]
    }
   ],
   "source": [
    "ip = issue_provider(ctx)  \n",
    "#ip.driver.quit()\n",
    "#ip.issues\n",
    "ip.parse_metrics(tnum='9495')\n",
    "#print(ip.issues.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ip.issues.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ctx.get_tempalte_dir()+'frmval.sql', 'r') as f:\n",
    "    s=f.read() \n",
    "df=sql_todf(\"\"\"\n",
    "SELECT DISTINCT IdText AS [{idt}], REPLACE(IdText, '.','_') [{var}], SortPos  FROM vwQuestions  \n",
    "WHERE PK_FORM = '2023-Q1-CIO'  AND IdText LIKE '2.%' AND Q_TypeID=2 \n",
    "ORDER BY SortPos;\n",
    " \n",
    "\"\"\", connstr) \n",
    "df['sql']=[s.replace('{idt}',x).replace('{var}',y) for x,y in zip(df['{idt}'], df['{var}'])]\n",
    " \n",
    "with open(ctx.get_dest()+'script.sql', 'w') as f:\n",
    "    f.write( '\\n'.join(list(df['sql'])) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_grid(tnum, pk, QCol='Question', PivotCols=4): \n",
    "    ip = issue_provider(ctx)\n",
    "    driver=ip.driver\n",
    "    driver.get(f\"https://dayman.cyber-balance.com/jira/si/jira.issueviews:issue-html/CS-{tnum}/CS-{tnum}.html\")   \n",
    "    ldf = pd.read_html(driver.page_source, match=\"\\d\\.\\d\\.\\d\", header=1)\n",
    "    df=ldf[0].iloc[:,:].rename(columns={QCol: \"QuestionText\"})\n",
    " \n",
    "    df['identifier_text'] = df['QuestionText'].apply(lambda s: re.findall('^[\\d\\.\\w]{1,7}',s)[0])\n",
    "    stypes = {k: chr(v+97) for v, k in enumerate(list(df.columns[1:4]))} \n",
    "    print(stypes)\n",
    "    df=df.loc[:,['QuestionText','identifier_text']] \n",
    "    df['CTRLCODE']='LABEL'\n",
    "    lod=df.to_dict(orient='records')\n",
    "    l=[]\n",
    "    for i,r in enumerate(lod):\n",
    "        l.append(lod[i])\n",
    "        for k in stypes.keys():\n",
    "            id=lod[i]['identifier_text']+'.'+stypes[k]\n",
    "            l.append({\n",
    "                'identifier_text':id\n",
    "                , 'QuestionText': id+' '+k\n",
    "                , 'CTRLCODE':'CNT'\n",
    "                })\n",
    "    df=pd.DataFrame(l)\n",
    "    df['{PK_Question}'] = range(pk,len(df)+pk)\n",
    "    df['sortpos'] = range(1,len(df)+1) \n",
    "    df['FK_QuestionType'] = df['CTRLCODE'].apply(lambda s: 2 if s=='CNT' else 18)\n",
    "    df['QuestionText']=df['QuestionText'].apply(lambda s: re.sub('^[\\d\\.\\w]{1,7}','',s, count=1).strip())\n",
    "    df['{QuestionText}']=df['QuestionText']\n",
    "    df['{idt}'] = df['identifier_text'].str.replace('.','_')\n",
    "    with open (ctx.get_tempalte_dir()+'fsma_QuestionsInsert.sql', 'r') as f:\n",
    "        df['sql']=f.read() \n",
    "    for i,r in df.iterrows():\n",
    "        for c in df.columns: \n",
    "            df.loc[i,'sql']= re.sub(str(c),str(df.loc[i,c]),df.loc[i,'sql'])  \n",
    "    sql='\\n,'.join(df['sql'])\n",
    "    with open(f'{ctx.get_dest()}script.sql', 'w') as f:\n",
    "        f.write(sql)\n",
    "\n",
    "    gen=script_generator(ctx)\n",
    "    code=gen.generate(df)\n",
    "    with open(f'{ctx.get_dest()}script.aspx', 'w') as f:\n",
    "        f.write(code)\n",
    "    \n",
    "    return df,sql,code\n",
    "\n",
    "# df,sql,code=parse_grid('9295',37400, QCol='Type of Test')\n",
    "# print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl=''\n",
    "with open(f'{ctx.get_tempalte_dir()}TXT_OPT.aspx', 'r') as f:\n",
    "    ctrl=f.read().replace('\\n','')\n",
    "\n",
    "def met_provider(s):  \n",
    "    if type(s) != str : return s\n",
    "    m=re.findall('\\d{1,2}\\.\\d{1,2}\\.?\\d{0,2}\\.?[\\.\\d\\w]?', s)  \n",
    "    return m[0] if len(m) > 0 else ''\n",
    "\n",
    "def cell_provider(s, i):  \n",
    "    if type(s) != str : return s\n",
    "    m=re.findall('\\d{1,2}\\.\\d{1,2}\\.?\\d{0,2}\\.?[\\.\\d\\w]?', s)\n",
    "    d={0:'a.i',1:'a.ii',2:'b.i',3:'b.ii',4:'c.i',5:'c.ii' } \n",
    "    idt=f'{m[0]}.{d[i]}'\n",
    "    c=ctrl.replace('{idt}',idt.replace('.','_'))\n",
    "    return f'{c}' if len(m) > 0 else ''\n",
    "\n",
    "def lbl_provider(s): \n",
    "    if type(s) != str : return s\n",
    "    lbl='<uc:CBlabel ID=\"CBlabel_{idt}_i\" PK_key=\"{idt}\" runat=\"server\" LabelType=\"Question\" />'   \n",
    "    m=re.findall('\\d{1,2}\\.\\d{1,2}\\.?\\d{0,2}\\.?[\\.\\d\\w]?', s) \n",
    "    idt=f'{m[0]}'\n",
    "    c=lbl.replace('{idt}',idt.replace('.','_'))\n",
    "    return c\n",
    "def get_ids():\n",
    "    dff=sql_todf(\"SELECT replace(idtext, '.','_') id, pk_question  FROM vwQuestions WHERE PK_QuestionGroup=4014\", ctx.config['connstr'])\n",
    "    print(dff.iloc[0])\n",
    "    ids = {k:v for k, v in zip(dff['id'], dff['pk_question'] )  }\n",
    "    return ids\n",
    "ids=get_ids()   \n",
    "list(ids.keys())[3:5] \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(r'C:\\Users\\Tim\\Documents\\CIO\\CIO_SECTION_2.xlsx',  sheet_name='All', header=0 ) # Enterprise Identities  # Public Identities \n",
    "\n",
    "#df.fillna('', inplace=True)\n",
    "#df.drop([0], axis=0, inplace=True)\n",
    "df.rename(columns={'Unnamed: 2':'.','Unnamed: 4':'..','Unnamed: 6':'...'}, inplace=True)\n",
    "for i,c in enumerate(df.columns[1:]): \n",
    "    df.loc[1:,c] = df.loc[1:, 'Question'].apply(lambda s:  cell_provider(s,i)  )\n",
    "\n",
    "#mets = [str(m)  for m in list(dff['m']) if '2' in str(m) ]  \n",
    "\n",
    "df['Question']=df['Question'].apply(lbl_provider )\n",
    "df.to_html(f'{ctx.get_dest()}parsed.html',index=False)\n",
    " \n",
    "s=''\n",
    "with open(f'{ctx.get_dest()}parsed.html', 'r') as f:\n",
    "    s=f.read()\n",
    "s=re.sub('<th>\\.{1,3}</th>','',s)\n",
    "s=re.sub('th>','td>',s) \n",
    "s=re.sub('<td>Number','<td colspan=\"2\">Number',s)\n",
    "\n",
    "s=re.sub('<thead>|</thead>|<tbody>|</tbody>','',s) \n",
    "for k in ids:\n",
    "    s=s.replace(f'PK_key=\"{k}\"',f'PK_key=\"{str(ids[k])}\"' )\n",
    "    s=s.replace(f'PK_Question=\"{k}\"',f'PK_Question=\"{str(ids[k])}\"' )\n",
    "with open(f'{ctx.get_dest()}script.html', 'w') as f: \n",
    "    s=html.unescape(s) \n",
    "    f.write(s)\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_sql(items=[], PK_PickListType=808, PK_PickList=9999, Description='[Description]', UsageField='[UsageField]', encoding=None):\n",
    "    if encoding == None:\n",
    "        encoding=lambda s: re.sub('[^A-Z0-9]','',s.upper().strip()[:15])  \n",
    "    plt=''\n",
    "    with open(f'{ctx.get_tempalte_dir()}plt.sql', 'r') as f:\n",
    "        plt=f.read()\n",
    "        plt=plt.replace('{PK_PickListType}',str(PK_PickListType))\n",
    "        plt=plt.replace('{Description}',Description)\n",
    "        plt=plt.replace('{UsageField}',UsageField)\n",
    "    pl=''\n",
    "    with open(f'{ctx.get_tempalte_dir()}picklists.sql', 'r') as f:\n",
    "        pl=f.read()\n",
    "    sql_items=[] \n",
    "    for i, item in enumerate(list(items)): \n",
    "        s=pl.replace('{PK_PickList}',str(PK_PickList+i))\n",
    "        s=s.replace('{CodeValue}',encoding(item))\n",
    "        s=s.replace('{DisplayValue}',str(item)) \n",
    "        s=s.replace('{SORT}',str(i+1)) \n",
    "        sql_items.append(s)\n",
    "    PK_PickList=PK_PickList+i+10\n",
    "    sql=plt.replace('{picklists.sql}','\\n,'.join(sql_items)[:])\n",
    "    return sql_items, sql\n",
    "l,sql = list_to_sql(['asdf asdf', '098a asdfasdfasdfasdfasdfasdfasdf @#$%'], Description='Desc', UsageField='UF')\n",
    "print(len(l))\n",
    "print(sql)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a7c076192e1e16d3ee1a218e6831777c4d2e3a001a9a33f6decd6c7672cec63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
