{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re \n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.corpus import stopwords \n",
    "sw=stopwords.words('english') \n",
    "from nltk.util import ngrams\n",
    "from lib.config import connstr\n",
    "from lib.utils import * \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_range=(2,3)\n",
    "def normalizer(s):\n",
    "    s=re.sub('[^a-z\\s\\-]','',s.lower())\n",
    "    s=re.sub('\\s{2,}',' ',s).strip()\n",
    "    return s\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj) \n",
    "    \n",
    "def vectorize(s, verbose=False):  \n",
    "    s=normalize(s)\n",
    "    if verbose: print(s)\n",
    "    vect=CountVectorizer(ngram_range=gram_range , analyzer='word' )\n",
    "    X = vect.fit_transform([s])\n",
    "    d={}\n",
    "    if verbose: print(vect.get_feature_names())\n",
    "    for f in vectorizer.get_feature_names(): \n",
    "        d[f]=0\n",
    "        if f in vect.get_feature_names():\n",
    "            d[f]=X.toarray()[0][vect.get_feature_names().index(f)-1] \n",
    "    with open('out.txt' , 'w') as f:\n",
    "        f.write(json.dumps(d, cls=NpEncoder, indent=2))\n",
    "    return d     \n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=gram_range, analyzer='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sql_todf(f\"\"\"\n",
    "    SELECT TOP 10000 PK_Question, FK_QuestionType, QuestionText\n",
    "    FROM fsma_Questions WHERE FK_QuestionType IS NOT NULL AND QuestionText IS NOT NULL  \n",
    "    AND FK_QuestionType IN (1,2,9,17,43) \n",
    "    AND PK_Question < 40000\n",
    "    ORDER BY PK_QUESTION DESC\n",
    "    \"\"\", connstr)   \n",
    "df['NQuestionText']=df['QuestionText'].apply(normalizer) \n",
    "df['NQuestionText'].dropna(inplace=True)\n",
    "    \n",
    "df['vecttext']=df['NQuestionText'].apply(lambda s: s.upper())   \n",
    "X = vectorizer.fit_transform(df['vecttext'])   \n",
    "dff = pd.DataFrame(columns=vectorizer.get_feature_names(), data=X.toarray()) \n",
    "sparse_matrix=pd.merge(df, dff, left_index=True, right_index=True)\n",
    "sparse_matrix\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sm_predict(s,threshold=.25): \n",
    "    s=normalizer(s)\n",
    "    print ( s )\n",
    "    dff=sparse_matrix.loc[:, ['FK_QuestionType','NQuestionText']]\n",
    "    for i,r in dff.iterrows():  \n",
    "        ratio=SequenceMatcher(None, s, str(r['NQuestionText']) ).ratio() \n",
    "        dff.loc[i, 'ratio'] = ratio\n",
    "        #if ratio > threshold: break\n",
    "    d=dff.loc[dff.ratio > threshold]\n",
    "    d=d.sort_values(by=['ratio'], ascending=False) \n",
    "    return d\n",
    "dfp=sm_predict(\"\"\"\n",
    "\n",
    "    How many chickens are classified as high value\n",
    "    \"\"\")\n",
    "dfp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=sparse_matrix.copy()\n",
    "dff.drop(['NQuestionText', 'QuestionText', 'PK_Question', 'vecttext'], inplace=True, axis=1)\n",
    "y = dff['FK_QuestionType'].values \n",
    "X = dff.drop(['FK_QuestionType' ], axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_question_type(s):\n",
    "    vectorized=vectorize(s)   \n",
    "    prediction=model.predict([list( vectorized.values() )])\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PK_QuestionType : 2\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_question_type(\n",
    "    \"\"\"\n",
    "    How many chickens are classified as angelo\n",
    "    \"\"\"\n",
    ")  \n",
    "print ('PK_QuestionType : '+ str(prediction))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
