{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re, json, os , logging , random, subprocess\n",
    "from lib.config import connstr\n",
    "from lib.context import context\n",
    "from lib.utils import * \n",
    "from lib.picklist_recommender import picklist_recommender\n",
    "from lib.issue_provider import issue_provider\n",
    "from lib.questionnaire_parser import questionnaire_parser\n",
    "from lib.questionnaire_picklist_parser import questionnaire_picklist_parser\n",
    "from lib.script_generator import script_generator   \n",
    "import nltk\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "sw=stopwords.words('english') \n",
    "ctx=context() \n",
    "ctx.logger.setLevel(logging.DEBUG)\n",
    "config = {}\n",
    "with open('config.json', 'r') as f: \n",
    "    config=json.loads(f.read())    \n",
    "ctx.config=config \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#df, code = generate_code_from_db(ctx, qgroup=4028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(s):\n",
    "    s=re.sub('\\s','',s)\n",
    "    return s \n",
    "sheet_name='Scan Metrics'\n",
    "df_template = pd.read_excel(r\"C:\\Users\\timko\\Downloads\\BOD2301Templates.xlsx\", header=0, sheet_name=sheet_name,  usecols='B:ZZ', dtype=str)   \n",
    "sheet_name=sheet_name.replace(' ', '')\n",
    "cols = list(df_template.columns)  \n",
    "fields = list(df_template.columns)  \n",
    "fields = list(map( lambda s:  s.replace('%','Per'), fields)) \n",
    "fields = list(map( normalize_var, fields)) \n",
    "fields = fields + ['FK_HOST_SCAN']\n",
    "s,p,c='','',''\n",
    "for field in fields:   \n",
    "    s += f'\\t, {field} \\n' \n",
    "    if 'Per' in field:\n",
    "        p += f'\\t, @{field} DECIMAL(10,2) = NULL \\n'  \n",
    "    elif 'FK_' in field:\n",
    "        p += f'\\t, @{field} NVARCHAR(100) = NULL \\n'  \n",
    "    else:\n",
    "        p += f'\\t, @{field} INT = NULL \\n' \n",
    " \n",
    "c = re.sub('=|@','',p) \n",
    "sql=''\n",
    "with open(r\"C:\\Users\\timko\\Desktop\\BOD2301_CDMDATA_CRUD.sql\", 'r' , encoding=\"utf8\", errors='replace') as f:\n",
    "    sql=f.read()\n",
    "sql=sql.replace('--@fields', p)\n",
    "sql=sql.replace('--fields', s)\n",
    "sql=sql.replace('--cols', c) \n",
    "sql=sql.replace('BOD2301_CDMDATA', 'BOD2301_CDM_'+sheet_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(r'C:\\dev\\CyberScope\\CyberScopeBranch\\CSwebdev\\database\\Sprocs\\datacall\\BOD2301_CDM_'+sheet_name+'_CRUD.sql', 'w', encoding='UTF-8') as f: \n",
    "    f.write( f'\\n{sql}' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df_template.columns:\n",
    "    f = c.replace('%','Per') \n",
    "    f = normalize_var(f)\n",
    "    print( f'\\t\\t<CB:DataField  DBColumnName=\"{f}\" Require=\"False\" ImportColumnName=\"{c}\" runat=\"server\"/>  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sql_todf(\"  SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME IN( 'vwCDMHostScan')  \", connstr)   \n",
    " \n",
    "for i,r in df.iterrows():\n",
    "    c=r['COLUMN_NAME']\n",
    "    col = \"\"\"  , c AS [c]\"\"\".replace('c', c)\n",
    "    print(f' {col} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sql_todf(\"  SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME IN(  'BOD2301_CDM_ScanMetrics')  \", connstr)   \n",
    " \n",
    "cols = df[2:]['COLUMN_NAME'].to_list()\n",
    "for f in cols:\n",
    "    col = \"\"\"  , {  field: \"1\", title: \"2\" }\"\"\"\n",
    "    col=col.replace('1',f)\n",
    "    col=col.replace('2',to_proper(f).replace('Percentage', ' pct.'))\n",
    "    print(col)\n",
    "    # print(f', {f} AS [{to_proper(f)}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sql_todf(\"  SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'BOD2301_CDM_HostMetrics'  \", connstr)   \n",
    " \n",
    "cols = df[2:]['COLUMN_NAME'].to_list()\n",
    "for f in cols:\n",
    "    col = \"\"\"  , {  field: \"1\", title: \"2\" }\"\"\"\n",
    "    col=col.replace('1',f)\n",
    "    col=col.replace('2',to_proper(f).replace('Percentage', ' pct.'))\n",
    "    print(col)\n",
    "    # print(f', {f} AS [{to_proper(f)}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = set(sql_todf(\"  SELECT Acronym FROM [Component List] WHERE IsActive=1 AND Component LIKE '%Administration%' AND FK_PK_Component IS NULL  \", connstr)['Acronym']) \n",
    "ag = list(ag)\n",
    "ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sql_todf(\"  SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'BOD2301_CDM_ScanMetrics'  \", connstr)   \n",
    "lod = []\n",
    "cols = df[2:31]['COLUMN_NAME'].to_list()\n",
    "for i in range(len(ag)):\n",
    "    d={}\n",
    "    for c in cols:\n",
    "        d[c]=random.randint(50, 100)\n",
    "        if 'Agency' in c:\n",
    "            d[c]=ag[i] + ''\n",
    "        if 'FK_HOST_SCAN' in c:\n",
    "            d[c]= 'FK_HOST_SCAN_1'\n",
    "            \n",
    "    lod.append(d)\n",
    "lod\n",
    "df = pd.DataFrame(lod) # .to_csv(r\"C:\\Users\\timko\\Downloads\\BOD2301_CDM_ScanMetrics.csv\", index=False)\n",
    "df.to_excel(rf'C:\\Users\\timko\\Downloads\\BOD2301_CDM_ScanMetrics.xlsx',  sheet_name='Scan Metrics', index=False) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntb = '<telerik:RadNumericTextBox ID=\"field\" runat=\"server\" MinValue=\"0\"/>'\n",
    "tb = '<asp:TextBox runat=\"server\" ID=\"field\" Value=\"\" />'\n",
    "lbl = '<asp:Label runat=\"server\" ID=\"field\" Text=\"\" />'\n",
    "frm , s = \"<tr> <td>{A}</td> <td>{B}</td> <td>{C}</td> <td>{D}</td> <td>{E}</td> <td>{F}</td> <td>{G}</td> <td>{H}</td>  </tr>\", ''\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, ss, u, uu = '','','',''\n",
    "for i, r in df.iterrows():\n",
    "    c = f'{normalize_var(r[\"COLUMN_NAME\"])}'  \n",
    "    field= r[\"COLUMN_NAME\"]\n",
    "    u += f\", CASE WHEN {field} < 0 THEN 'DNS' ELSE {field} END AS {field}_DISPLAY -- DNS (DID NOT RESPOND)\\n\"\n",
    "    if re.match('.*App.*|.*CDMP.*', c):\n",
    "        s +=  f\", {field} \" # \\n\" \n",
    "        ss +=  f\", {i}\" # f\", @{field} \\n\" \n",
    "    if 'DATE' in r[\"DATA_TYPE\"]:\n",
    "        uu += f\", FORMAT({field}, 'MM/dd/yyyy') AS {field} \\n\" \n",
    "    else:\n",
    "        uu += f', {field} \\n'\n",
    "print(s)\n",
    "print(ss) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in df.iterrows():\n",
    "    c = f'{normalize_var(r[\"COLUMN_NAME\"])}' \n",
    "    dfld = f'<CB:DataField  DBColumnName=\"{c}\" Require=\"False\" ImportColumnName=\"{c}\" runat=\"server\"/>  '\n",
    "    if 'Perc' in c:\n",
    "        dfld = f'<CB:DataField  DBColumnName=\"{c}\" Require=\"False\" DataType=\"System.DateTime\" NonDatePlaceholder=\"01/01/1900\" ImportColumnName=\"{c}\"  runat=\"server\"/>  '\n",
    "    # print(s) \n",
    "    print(dfld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for c in df.columns:\n",
    "    n = f'{normalize_var(c)}' \n",
    "    s = f',{n} NVARCHAR(MAX) NULL ' \n",
    "    # print(s)\n",
    "    dfld = f'<CB:DataField  DBColumnName=\"{n}\" Require=\"False\" ImportColumnName=\"{c}\" runat=\"server\"/>  '\n",
    "    if c[-4:] == \"Date\":\n",
    "        dfld = f'<CB:DataField  DBColumnName=\"{n}\" Require=\"False\" DataType=\"System.DateTime\" NonDatePlaceholder=\"01/01/1900\" ImportColumnName=\"{c}\"  runat=\"server\"/>  '\n",
    "    print(dfld )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", '' AS [Agency Name] \n",
      ", '' AS [Agency] \n",
      ", '' AS [Submission Date] \n",
      ", '' AS [CDM  Assets Discovered] \n",
      ", '' AS [Appended  Assets Discovered] \n",
      ", '' AS [CDM  Vulnerability Enumeration] \n",
      ", '' AS [Appended  Vulnerability Enumeration] \n",
      ", '' AS [CDM Credentialed Scan] \n",
      ", '' AS [Appended Credentialed Scan] \n",
      ", '' AS [CDM Endpoints] \n",
      ", '' AS [Appended Endpoints] \n",
      ", '' AS [CDM Networking Devices] \n",
      ", '' AS [Appended Networking Devices] \n",
      ", '' AS [CDM Mobile Devices] \n",
      ", '' AS [Appended Mobile Devices] \n",
      ", '' AS [CDM Unknown] \n",
      ", '' AS [Appended Unknown] \n",
      ", '' AS [CDM Other IO Devices] \n",
      ", '' AS [Appended Other IO Devices] \n",
      ", '' AS [CDM Vulnerability Signatures] \n",
      ", '' AS [Appended Vulnerability Signatures] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_excel(r'C:\\Users\\timko\\Downloads\\BOD 23-01 - Calculations and Data Sources - 061225.xlsx', sheet_name='Custom Query', header=0, usecols='A:Z' )  \n",
    "df.columns=[c.replace('\\n' ,' ') for c in df.columns] \n",
    "for c in df.columns:\n",
    "    print(f\", '' AS [{c}] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\Tim\\Downloads\\fedramp.xlsx', sheet_name='Agency - CSP Table', header=1, usecols='B:Z' )  \n",
    "df.columns=[c.replace(' ' ,'') for c in df.columns] \n",
    "df\n",
    "# df.to_excel(r'C:\\Users\\Tim\\Downloads\\fedramp_admin_import.xlsx', sheet_name='Admin Import', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\timko\\Downloads\\TLP RED - FY25 HVA List - CyberScope Upload.xlsx', sheet_name='Export', header=0, usecols='A:Z' )   \n",
    "df['PK_HVA'] = df['HVA_ID'].apply(id)\n",
    "df['TierPK'] = df['Tier'].apply(tier)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "up = \"UPDATE fsma_HVAs SET Tier='t', AgencyRank='ar' WHERE PK_HVA = 'pk' ;\"\n",
    "sql=''\n",
    "for i, row in df[:].iterrows():\n",
    "    s=up.replace(\"'t'\", row[\"TierPK\"])\n",
    "    s=s.replace(\"'pk'\", row[\"PK_HVA\"])\n",
    "    s=s.replace(\"'ar'\", str(row[\"Rank within FHE\"]))\n",
    "    \n",
    "    sql=sql+s+'\\n'\n",
    "print( sql )\n",
    "\n",
    "\n",
    "with open(r'y:\\tkopp\\tscript.sql', 'w', encoding='UTF-8') as f: \n",
    "    f.write( f'\\n{sql}' ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = pd.read_csv(f'{ctx.get_dest()}fedramp.csv') \n",
    "df=normalizedf(fields)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = set(sql_todf(\"  SELECT Component FROM [Component List] WHERE IsActive=1 AND FK_PK_Component IS NULL  \", connstr)['Component']) \n",
    "ag = set(ag)\n",
    "ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df[:].iterrows():\n",
    "    s=f\",@{row['COLUMN_NAME']} {row['DATA_TYPE']}\"\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_fromTemplateColumn(path): \n",
    "    lst=[]\n",
    "    cols=[]\n",
    "    with open(path, 'r') as f:  \n",
    "        g=re.search(\"<Columns>(.*)<\\/Columns\", f.read() , flags=re.DOTALL)   \n",
    "        lst=g.groups(0)[0].split('<CB:CBGridTemplateColumn')[1:] \n",
    "        for l in lst: \n",
    "            un = re.search('UniqueName=\"(\\w+)\"\\s', l ).groups(0)[0] \n",
    "            ht = un\n",
    "            if 'HeaderText' in l:\n",
    "                try: ht = re.search('HeaderText=\"([A-Za-z\\s]*)\"', l ).groups(0)[0]  \n",
    "                except:  pass \n",
    "            cols.append({  'UniqueName': un ,'HeaderText':ht   })\n",
    "            \n",
    "    return pd.DataFrame(cols)\n",
    "df = df_fromTemplateColumn(r'C:\\dev\\CyberScope\\CyberScopeBranch\\CSwebdev\\code\\CyberScope\\BODSCuBA\\2024\\2024_A_SCuBATenantInventory_1.aspx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i,r in df.iterrows(): \n",
    "    un = r['UniqueName'] \n",
    "    ht = r['HeaderText'] \n",
    "    s = f'<CB:DataField  DBColumnName=\"{un.replace(\" \",\"\")}\" Require=\"False\" ImportColumnName=\"{ht}\" runat=\"server\"/>  '\n",
    "    if \"Date\" in un: \n",
    "        s = f'<CB:DataField  DBColumnName=\"{un.replace(\" \",\"\")}\" Require=\"False\" ImportColumnName=\"{ht}\"  runat=\"server\"/>  '\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in df.iterrows(): \n",
    "    DATA_TYPE=r[\"DATA_TYPE\"]\n",
    "    COLUMN_NAME=r[\"COLUMN_NAME\"]\n",
    "    HEADER=r[\"HEADER\"]\n",
    "    PK_PICKLISTTYPE=str(r[\"PK_PICKLISTTYPE\"] )\n",
    "    s=f'<CB:DataField DBColumnName=\"{COLUMN_NAME}\" ImportColumnName=\"{HEADER}\" SprocParamName=\"{COLUMN_NAME}\" runat=\"server\"/>' \n",
    "    s=f',{COLUMN_NAME} '\n",
    "    if PK_PICKLISTTYPE != '0': s=s.replace('runat',' PickListTypeID=\"'+ PK_PICKLISTTYPE +'\" runat')   \n",
    "    \n",
    "    e=f',{COLUMN_NAME} AS [{HEADER}] '\n",
    "    if PK_PICKLISTTYPE != '0': e=f', (SELECT DisplayValue FROM vwPICKLISTS WHERE PK_Picklist={COLUMN_NAME}) AS [{HEADER}]' \n",
    "    if 'Date' in COLUMN_NAME:\n",
    "        e=f\" , CASE WHEN {COLUMN_NAME} LIKE '%2000%' THEN 'NA' ELSE FORMAT({COLUMN_NAME}, 'MM/dd/yyyy') END AS [{HEADER}]\"\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, row in df[:].iterrows():\n",
    "    with open(ctx.get_tempalte_dir()+'GridTemplateColumn.aspx', 'r') as f: \n",
    "        s=f.read()  \n",
    "    DATA_TYPE=row['DATA_TYPE']\n",
    "    COLUMN_NAME=row['COLUMN_NAME']\n",
    "    HEADER=row['HEADER']\n",
    "    PK_PICKLISTTYPE=row['PK_PICKLISTTYPE']\n",
    "    s=s.replace('{COLUMN_NAME}', COLUMN_NAME)\n",
    "    if 'INT' in DATA_TYPE:  \n",
    "        s=s.replace('{Bind_COLUMN_NAME}', COLUMN_NAME+'_Display')\n",
    "        s=s.replace('<%-- --%>', f'<telerik:RadDropDownList ID=\"{COLUMN_NAME}\" DataValueField=\"YN\" runat=\"server\" />')  \n",
    "    else:\n",
    "        s=s.replace('{Bind_COLUMN_NAME}', COLUMN_NAME )\n",
    "        if 'Date' in COLUMN_NAME:  \n",
    "            # print(\"const \"+COLUMN_NAME+\" = new CBDatePicker({ id: $(`[id$=_\"+COLUMN_NAME+\"]`).prop('id'), allowNa: true  }); \")  \n",
    "            s=s.replace('<%-- --%>', f'<asp:HiddenField ID=\"{COLUMN_NAME}\" runat=\"server\" />') \n",
    "        else: \n",
    "            s=s.replace('<%-- --%>', f'<telerik:RadTextBox ID=\"{COLUMN_NAME}\" runat=\"server\" />') \n",
    "    #print(f\"[{COLUMN_NAME}] [NVARCHAR](4000) NULL,\")  \n",
    "    #print('{ field: \"'+COLUMN_NAME+'\", title: \"'+HEADER+'\" },')\n",
    "    print (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def get_gridcols(df,out=False):\n",
    "    ldf=df.to_dict(orient='records') \n",
    "    code,ddl,dv,sel,dtf=[],[],[],[],[]\n",
    "    with open(ctx.get_tempalte_dir()+'GridTemplateColumn.aspx', 'r') as f: \n",
    "        t=f.read() \n",
    "        \n",
    "        for d in ldf: \n",
    "            col=d['COLUMN_NAME'] \n",
    "            s=t.replace(\"{COLUMN_NAME}\",d['COLUMN_NAME'])  \n",
    "            if 'INT' in d['DATA_TYPE'].upper():\n",
    "                s=s.replace('{Bind_COLUMN_NAME}',f\"{d['COLUMN_NAME']}_Display\")\n",
    "                s=s.replace('<%-- --%>', f'<telerik:RadDropDownList ID=\"{col}\" DataValueField=\"YN\" runat=\"server\" />')\n",
    "                ddl.append(f'BindDDL(e, \"{col}\", \"{col}\", \"{col}\")')\n",
    "                sel.append(f',(SELECT DisplayValue FROM vwPICKLISTS WHERE PK_Picklist={col}) AS {col}') \n",
    "            else: \n",
    "                s=s.replace('{Bind_COLUMN_NAME}',f\"{d['COLUMN_NAME']}\")\n",
    "                s=s.replace('<%-- --%>', f'<telerik:RadTextBox ID=\"{col}\" runat=\"server\" />')\n",
    "                dv.append(f'DirectCast(e.Item.FindControl($\"{col}\"), RadTextBox).Text = drVal(\"{col}\").ToString()')\n",
    "                sel.append(f',{col}') \n",
    "            code.append(f'{s}')     \n",
    "    code='\\n'.join(code) \n",
    "    ddl='\\n'.join(ddl)\n",
    "    dv= '\\n'.join(dv)\n",
    "    sel= '\\n'.join(sel)[1:] \n",
    "    return {'code':code, 'ddl':ddl,'dv':dv,'sel':sel, 'dtf': dtf}\n",
    "  \n",
    " \n",
    "p = get_gridcols(df, out=False)\n",
    "p\n",
    "print ( p['code'] ) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = get_gridcols(df)\n",
    "print( sql['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql(df,out=False):\n",
    "    parms=[]\n",
    "    for i,r in df.iterrows():\n",
    "        s=f\"@{r['COLUMN_NAME']} {r['DATA_TYPE'].upper()}({r['CHARACTER_MAXIMUM_LENGTH']}) = NULL\"\n",
    "        if r['DATA_TYPE'].upper() == 'INT':\n",
    "            s=f\"@{r['COLUMN_NAME']} {r['DATA_TYPE'].upper()} = NULL\"  \n",
    "        parms.append(f',{s}')\n",
    "\n",
    "    into=', '.join([c for c in df['COLUMN_NAME'] if 'PK_' not in c])\n",
    "    vals=', @'.join([c for c in df['COLUMN_NAME'] if 'PK_' not in c]) \n",
    "    ins=f'\\n INSERT INTO @TABLE ({into}) \\n VALUES (@{vals})'\n",
    "\n",
    "    parms='\\n'.join(parms)[:] \n",
    "    update=', '.join([f'{c}=@{c}' for c in df['COLUMN_NAME'] if 'PK_' not in c ])  \n",
    "    ext=' AND ' + ' AND '.join([f'{c}=@{c}' for c in df['COLUMN_NAME'] if 'PK_' not in c ])\n",
    "\n",
    "    sel=[] \n",
    "    exp=[]\n",
    "    for i,r in df.iterrows():   \n",
    "        s=f\"\\n, {r['COLUMN_NAME']} \"\n",
    "        if r['DATA_TYPE'].upper() == 'INT':   \n",
    "            s=s+f\"\\n, (SELECT DisplayValue FROM vwPicklists WHERE PK_Picklist={r['COLUMN_NAME']}) AS [{r['COLUMN_NAME']}_Display]\" \n",
    "            exp.append(f\"\\n, (SELECT DisplayValue FROM vwPicklists WHERE PK_Picklist={r['COLUMN_NAME']}) AS [{r['HEADER']}]\")\n",
    "        elif r['DATA_TYPE'].upper() == 'DATETIME':\n",
    "            s=s+f\"\\n, FORMAT({r['COLUMN_NAME']}, 'MM/dd/yyyy') AS [{r['COLUMN_NAME']}_Display] \" \n",
    "            exp.append(f\"\\n, FORMAT({r['COLUMN_NAME']}, 'MM/dd/yyyy') AS [{r['HEADER']}]\") \n",
    "        else:\n",
    "            exp.append(f\"\\n, {r['COLUMN_NAME']} AS [{r['HEADER']}]\")\n",
    "        sel.append(''+s)\n",
    "    sel=''.join(sel)  \n",
    "    exp=''.join(exp)  \n",
    "    return {'parms':parms,'ins':ins, 'update':update, 'sel':sel, 'ext':ext, 'exp':exp  }\n",
    "\n",
    "\n",
    "# df = sql_todf(\"SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME='FEDRAMP_UPLOAD'\", ctx.connstr) \n",
    "# df = normalizedf(df) \n",
    "#  df.columns\n",
    "d=get_sql(df, out=False)\n",
    "print( d['ins'].replace(',','\\n,')  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a7c076192e1e16d3ee1a218e6831777c4d2e3a001a9a33f6decd6c7672cec63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
