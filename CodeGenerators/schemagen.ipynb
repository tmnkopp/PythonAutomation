{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re, json, os , logging , random, html, datetime, openpyxl \n",
    "from lib.config import connstr\n",
    "from lib.context import context\n",
    "from lib.utils import * \n",
    "from lib.picklist_recommender import picklist_recommender\n",
    "from lib.issue_provider import issue_provider\n",
    "from lib.questionnaire_parser import questionnaire_parser\n",
    "from lib.questionnaire_picklist_parser import questionnaire_picklist_parser\n",
    "from lib.script_generator import script_generator   \n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "sw=stopwords.words('english') \n",
    "ctx=context() \n",
    "ctx.logger.setLevel(logging.DEBUG)\n",
    "config = {}\n",
    "with open('config.json', 'r') as f: \n",
    "    config=json.loads(f.read())    \n",
    "ctx.config=config \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#df, code = generate_code_from_db(ctx, qgroup=4028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(r'C:\\Users\\timko\\Downloads\\2302.xlsx', sheet_name=0, header=0, usecols='A:Z',index_col=0).reset_index()\n",
    "for c in df.columns:\n",
    "    df.rename({c: re.sub('','',c.strip())}, axis=1, inplace=True)\n",
    "    if 'Unnamed' in c: df.drop(columns=c, inplace=True)\n",
    "df.to_csv(r'C:\\Users\\timko\\Downloads\\2302-0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=sql_todf(\"\"\"\n",
    "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS  \n",
    "WHERE TABLE_NAME = 'PQCInventory'  \n",
    "\"\"\", connstr)   \n",
    "cols2 = set(df.COLUMN_NAME)\n",
    "cols2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf = pd.read_csv(f'{ctx.get_dest()}ldf.csv').loc[:,['col','icn']] \n",
    "df=sql_todf(\"\"\"\n",
    "SELECT * FROM INFORMATION_SCHEMA.COLUMNS \n",
    "LEFT JOIN PickListTypes ON UsageField=COLUMN_NAME\n",
    "WHERE TABLE_NAME = 'PQCInventory'  \n",
    "\"\"\", connstr)   \n",
    " \n",
    "df = normalizedf(df)\n",
    "df = pd.merge(df,ldf, left_on='COLUMN_NAME', right_on='col')\n",
    "#df.loc[df['PK_PickListType'] != '0']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(65,91):\n",
    "    print( f', @{chr(i)} NVARCHAR(4000)=NULL' )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A Number of vulnerability disclosure reports\t1\n",
    "B Number of reported vulnerabilities determined to be valid (e.g., in scope and not false-positive)\t2\n",
    "C Number of currently open and valid reported vulnerabilities\t3\n",
    "D Median age (in days from receipt of the report) of currently open and valid reported vulnerabilities\t4\n",
    "E Number of currently open and valid reported vulnerabilities older than 90 days from the receipt of the reportÂ \t5\n",
    "F Number of all reports older than 90 days by risk/priority level\t6\n",
    "\n",
    "G Median age (in days) of reports older than 90 days\t7\n",
    "H Median time (in days) to validate a submitted report\t8\n",
    "I Median time (in days) to remediate/mitigate a valid report\t9\n",
    "J Median time (in days) to initially respond to the reporter\t10\n",
    "How many reports are Critical\t6.1\n",
    "How many reports are High\t6.2\n",
    "How  many reports are Medium\t6.3\n",
    "How many reports are Low\t6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(r'C:\\Users\\timko\\Downloads\\BOD 20-01 VDP - Prepop.xlsx', header=0, usecols='A:R',index_col=0).reset_index()\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "for i,c in enumerate(df.columns):\n",
    "    s=re.sub('[^A-Za-z0-9]','',c.strip())\n",
    "    cb=f'<CB:DataField DBColumnName=\"{chr(i+65)}\" SheetColumnLetter=\"{chr(i+65)}\" runat=\"server\"/>'\n",
    "    print(\n",
    "       c # cb # f'{ chr(i+65)} {c} {s}'\n",
    "    )\n",
    "    # print( f', @{s} NVARCHAR(4000)=NULL' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_datafield(df, out=False):\n",
    "    txt=[]   \n",
    "    for i,r in df.iterrows():\n",
    "        plt=''\n",
    "        PK_PickListType=r['PK_PickListType']\n",
    "        COLUMN_NAME=r['COLUMN_NAME']\n",
    "        icn=r['icn']\n",
    "        DATA_TYPE=r['DATA_TYPE'] \n",
    "        if PK_PickListType != '0':  \n",
    "            plt=f' PK_PickListType=\"{PK_PickListType}\" '\n",
    "        s=f'<CB:DataField DBColumnName=\"{COLUMN_NAME}\" ImportColumnName=\"{icn}\" {plt} runat=\"server\"/>'\n",
    "        \n",
    "        txt.append(f'{s}')\n",
    "    txt='\\n'.join(txt) \n",
    "    with open(f'{ctx.get_dest()}script.aspx', 'w', encoding='UTF-8') as fw:\n",
    "        fw.write(txt)\n",
    "    if out: print(txt)\n",
    "    return txt\n",
    "\n",
    "def get_params(df,out=False):\n",
    "    parms=[]\n",
    "    for i,r in df.iterrows():\n",
    "        s=f\"@{r['COLUMN_NAME']} {r['DATA_TYPE'].upper()}({r['CHARACTER_MAXIMUM_LENGTH']}) = NULL\"\n",
    "        if r['DATA_TYPE'] == 'INT':\n",
    "            s=f\"@{r['COLUMN_NAME']} {r['DATA_TYPE'].upper()} = NULL\" \n",
    "        parms.append(f',{s}')\n",
    "\n",
    "    into=', '.join([c for c in df['COLUMN_NAME'] if 'PK_PQCInventory' not in c])\n",
    "    vals=', @'.join([c for c in df['COLUMN_NAME'] if 'PK_PQCInventory' not in c]) \n",
    "    ins=f'\\n\\n \\t\\t \\t\\t INSERT INTO PQCInventory ({into})'\n",
    "    ins=ins+f'\\n \\t\\t \\t\\t VALUES (@{vals})'\n",
    "\n",
    "    parms='\\n\\t\\t'.join(parms)[:]\n",
    "  \n",
    "    update=', '.join([f'{c}=@{c}' for c in df['COLUMN_NAME'] if 'PK_' not in c ]) \n",
    "\n",
    "    ext='\\t\\t \\t\\t AND ' + ' AND '.join([f'{c}=@{c}' for c in df['COLUMN_NAME'] if 'PK_' not in c ])\n",
    "\n",
    "    sel,exp=[],[]\n",
    "    for i,r in df.iterrows():\n",
    "        s=f\", {r['COLUMN_NAME']} \"\n",
    "        ex=f\", {r['COLUMN_NAME']} AS [{r['icn']}]\"\n",
    "        if r['DATA_TYPE'] == 'INT':\n",
    "            s=f\", (SELECT DisplayValue FROM vwPicklists WHERE PK_Picklist={r['COLUMN_NAME']}) AS [{r['COLUMN_NAME']}]\" \n",
    "            ex=f\", (SELECT DisplayValue FROM vwPicklists WHERE PK_Picklist={r['COLUMN_NAME']}) AS [{r['icn']}]\" \n",
    "        sel.append(f'{s}')\n",
    "        exp.append(f'{ex}')\n",
    "    sel='\\t\\t \\t\\t'+'\\n \\t\\t \\t\\t'.join(sel)\n",
    "    exp='\\t\\t \\t\\t'+'\\n \\t\\t \\t\\t'.join(exp)\n",
    "    with open(f'{ctx.get_dest()}script.sql', 'w', encoding='UTF-8') as fw:\n",
    "        fw.write(parms)\n",
    " \n",
    "    return {'parms':parms,'ins':ins, 'update':update, 'sel':sel, 'ext':ext , 'exp':exp  }\n",
    "\n",
    "def get_gridcols(df,out=False):\n",
    "    ldf=df.to_dict(orient='records') \n",
    "    txt,ddl,dv,sel=[],[],[],[] \n",
    "    with open(ctx.get_tempalte_dir()+'GridTemplateColumn.aspx', 'r') as f: \n",
    "        t=f.read() \n",
    "        for d in ldf: \n",
    "            col=d['col']\n",
    "            s=t.replace(\"{col}\",d['col']).replace(\"{ht}\",d['icn'])\n",
    "            sel.append(f',{col}')\n",
    "            if d['PK_PickListType'] != '0':\n",
    "                s=s.replace('<%-- --%>', f'<telerik:RadDropDownList ID=\"{col}\" runat=\"server\" />')\n",
    "                ddl.append(f'BindDDL(e, \"{col}\", \"{col}\", \"{col}\")')\n",
    "            else:\n",
    "                s=s.replace('<%-- --%>', f'<telerik:RadTextBox ID=\"{col}\" runat=\"server\" />')\n",
    "                dv.append(f'DirectCast(e.Item.FindControl($\"{col}\"), RadTextBox).Text = drVal(\"{col}\").ToString()')\n",
    "            txt.append(f'{s}')     \n",
    "    txt='\\n'.join(txt) \n",
    "    ddl='\\n'.join(ddl)\n",
    "    dv= '\\n'.join(dv)\n",
    "    sel= '\\n'.join(sel)[1:]\n",
    "    with open(f'{ctx.get_dest()}script.aspx', 'w', encoding='UTF-8') as fw:\n",
    "        fw.write(f'{txt} \\n\\n {ddl} \\n\\n {dv} \\n\\n {sel}')\n",
    "    if out:  print(txt)\n",
    "    return {'txt':txt, 'ddl':ddl,'dv':dv,'sel':sel}\n",
    "  \n",
    "def normalizedf(df):\n",
    "    df.drop( columns=[c for c in df.columns if '__' in c ] , inplace=True )   \n",
    "    cols = list(df)   \n",
    "    df['DATA_TYPE']=df['DATA_TYPE'].str.upper() \n",
    "    df['PK_PickListType']=df['PK_PickListType'].fillna(0).astype(int)\n",
    "    df['CHARACTER_MAXIMUM_LENGTH']=df['CHARACTER_MAXIMUM_LENGTH'].fillna(0).astype(int)\n",
    "    df[cols] = df[cols].astype(str)\n",
    "    df=df.loc[:, ['COLUMN_NAME','DATA_TYPE','CHARACTER_MAXIMUM_LENGTH','PK_PickListType']]\n",
    "    return df\n",
    " \n",
    "#p = get_params(df, out=False)\n",
    "#print ( p['exp'] ) \n",
    "get_datafield(df, out=True) \n",
    "#d=get_params(df, out=False)\n",
    "#print(d['sel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=get_params(df, out=False)\n",
    "with open(r'C:\\dev\\CyberScope\\CyberScopeBranch\\CSwebdev\\database\\Sprocs\\PQCInventory_CRUD.sql', 'r', encoding='UTF-8') as f:\n",
    "    sql=f.read()\n",
    "with open(r'C:\\dev\\CyberScope\\CyberScopeBranch\\CSwebdev\\database\\Sprocs\\PQCInventory_CRUD.sql', 'w', encoding='UTF-8') as f:\n",
    "    sql=re.sub('--parms(?s).*--~parms',f'--parms\\n{d[\"parms\"]}\\n\\t\\t--~parms', sql)\n",
    "    sql=re.sub('--sel(?s).*--~sel',f'--sel\\n{d[\"sel\"]}\\n\\t\\t--~sel', sql)\n",
    "    sql=re.sub('--ins(?s).*--~ins',f'--ins\\n{d[\"ins\"]}\\n\\t\\t--~ins', sql)\n",
    "    sql=re.sub('--update(?s).*--~update',f'--update\\n{d[\"update\"]}\\n\\t\\t--~update', sql)\n",
    "    sql=re.sub('--ext(?s).*--~ext',f'--ext\\n{d[\"ext\"]}\\n\\t\\t--~ext', sql)\n",
    "    f.write(sql)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=get_params(df, out=False)\n",
    "with open(r'C:\\dev\\CyberScope\\CyberScopeBranch\\CSwebdev\\database\\Sprocs\\PQCInventory_CRUD.sql', 'r', encoding='UTF-8') as f:\n",
    "    sql=f.read()\n",
    "with open(r'C:\\dev\\CyberScope\\CyberScopeBranch\\CSwebdev\\database\\Sprocs\\PQCInventory_CRUD.sql', 'w', encoding='UTF-8') as f:\n",
    "    sql=re.sub('--parms(?s).*--~parms',f'--parms\\n{d[\"parms\"]}\\n--~parms\\n', sql)\n",
    "    sql=re.sub('--sel(?s).*--~sel',f'--sel\\n{d[\"sel\"]}\\n--~sel\\n', sql)\n",
    "    sql=re.sub('--ins(?s).*--~ins',f'--ins\\n{d[\"ins\"]}\\n--~ins\\n', sql)\n",
    "    sql=re.sub('--update(?s).*--~update',f'--update\\n{d[\"update\"]}\\n--~update\\n', sql)\n",
    "    f.write(sql)\n",
    "#print(sql)\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=get_gridcols(df, out=False)\n",
    "print ( d['sel'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=get_gridcols(df, out=False)\n",
    "with open(r'C:\\dev\\CyberScope\\CyberScopeBranch\\CSwebdev\\code\\CyberScope\\CustomControls\\PQCInventory.ascx', 'r', encoding='UTF-8') as f:\n",
    "    aspx=f.read()\n",
    "with open(r'C:\\dev\\CyberScope\\CyberScopeBranch\\CSwebdev\\code\\CyberScope\\CustomControls\\PQCInventory.ascx', 'w', encoding='UTF-8') as f:\n",
    "    aspx=re.sub('<%-- cols --%>(?s).*<%-- ~cols --%>',f'<%-- cols --%>\\n{d[\"txt\"]}\\n<%-- ~cols --%>\\n', aspx)\n",
    "    f.write(aspx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a7c076192e1e16d3ee1a218e6831777c4d2e3a001a9a33f6decd6c7672cec63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
