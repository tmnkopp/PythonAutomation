{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re, json, os , logging , random, subprocess\n",
    "from lib.config import connstr\n",
    "from lib.context import context\n",
    "from lib.utils import * \n",
    "from lib.picklist_recommender import picklist_recommender\n",
    "from lib.issue_provider import issue_provider\n",
    "from lib.questionnaire_parser import questionnaire_parser\n",
    "from lib.questionnaire_picklist_parser import questionnaire_picklist_parser\n",
    "from lib.script_generator import script_generator   \n",
    "import nltk\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "sw=stopwords.words('english') \n",
    "ctx=context() \n",
    "ctx.logger.setLevel(logging.DEBUG)\n",
    "config = {}\n",
    "with open('config.json', 'r') as f: \n",
    "    config=json.loads(f.read())    \n",
    "ctx.config=config \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#df, code = generate_code_from_db(ctx, qgroup=4028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=sql_todf(\"  SELECT COLUMN_NAME, TABLE_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME IN ('fsma_FormMaster', 'fsma_DataCall', 'fsma_FormTypes', 'fsma_Reportingcycles') \", connstr)     \n",
    "for i,r in df.iterrows():\n",
    "    cn=r['COLUMN_NAME']\n",
    "    tn=re.sub('[a-z]|_','',r['TABLE_NAME'])\n",
    "    print(f\"\\t, {tn}.{cn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"DECLARE @ANS_6_1_1 NVARCHAR(99) = (SELECT CASE @PK_QuestionGroup WHEN 0 THEN TableAns ELSE MetricAns END FROM @ListofQuestions2 WHERE identifier_text IN ('6.1.1'))\"\n",
    "\n",
    "m=''\n",
    "for i in range(1,8):\n",
    "    m=m+f\"\\nDECLARE @ANS_6_{i}_1 NVARCHAR(99) = (SELECT CASE @PK_QuestionGroup WHEN 0 THEN TableAns ELSE MetricAns END FROM @ListofQuestions2 WHERE identifier_text IN ('6.{i}.1'))\"\n",
    "    m=m+f'''\\nIF @ANS_6_{i}_1 IS NOT NULL \n",
    "    BEGIN\\n'''\n",
    "    for c in 'abc': \n",
    "        m=m+f\"\\tDECLARE @ANS_6_{i}_1_{c} NVARCHAR(99) = (SELECT CASE @PK_QuestionGroup WHEN 0 THEN TableAns ELSE MetricAns END FROM @ListofQuestions2 WHERE identifier_text IN ('6.{i}.1.{c}'))\"\n",
    "        m=m+f'''\n",
    "            IF @ANS_6_{i}_1_{c} IS NULL\n",
    "            BEGIN\n",
    "                INSERT INTO @ErrorTable  \n",
    "                SELECT  PK_Question, PK_FormPage, page_sort_pos, questgroup_sort_pos, quest_sort_pos\n",
    "                , (identifier_text + ' needs a value') Error, identifier_text\n",
    "                FROM vw_OrgSubQuestions WHERE  identifier_text='6.{i}.1.{c}' AND PK_OrgSubmission = @PK_OrgSubmission  \n",
    "            END\n",
    "        '''\n",
    "    m=m+f'END'\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sql_todf(\"   SELECT PK_Question, QGROUP, IdText, sortpos, 70420 as new FROM vwQuestions WHERE PK_FORM = '2025-Q1-CIO' ORDER BY QGROUP, sortpos \", connstr)     \n",
    "qg = df.iloc[0]['QGROUP']\n",
    "inc = 0\n",
    "dic = {}\n",
    "lod = []\n",
    "for i,r in df.iterrows():\n",
    "    inc=inc+1\n",
    "    if qg != df.iloc[i]['QGROUP']:\n",
    "        qg = df.iloc[i]['QGROUP']\n",
    "        inc=inc+4 \n",
    "    n=df.iloc[i]['new'] \n",
    "    dic[str(df.iloc[i]['PK_Question']) ] = str(df.iloc[i]['new'] + inc)\n",
    "    lod.append({'pk':str(df.iloc[i]['PK_Question']) , 'new':str(df.iloc[i]['new'] + inc)})\n",
    "dff=pd.DataFrame(lod)\n",
    "dff.to_json(r'C:\\Users\\timko\\source\\repos\\SledgeOmatic\\SledgeOMatic\\Tasks\\cio-keys.json', orient='records')\n",
    "dff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(r'C:\\Users\\timko\\source\\repos\\SledgeOmatic\\SledgeOMatic\\Tasks\\keys.json', 'w', encoding='UTF-8') as f: \n",
    "    f.write( f'{str(json.dumps(dic))}' ) \n",
    "\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dff=pd.DataFrame([ dic]) \n",
    "#dff.to_json(r'C:\\Users\\timko\\source\\repos\\SledgeOmatic\\SledgeOMatic\\Tasks\\keys.json', orient='records' )\n",
    "dff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\Tim\\Downloads\\FedRAMP Cloud Services - 081224 (1).xlsx', sheet_name='Agency Upload Template', header=0, usecols='A:Z' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sql_todf(\"  SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'CDMInfoSys'  \", connstr)   \n",
    "df=normalize_if_df(df) \n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in df.iterrows():\n",
    "    c = f'{normalize_var(r[\"COLUMN_NAME\"])}' \n",
    "    dfld = f'<CB:DataField  DBColumnName=\"{c}\" Require=\"False\" ImportColumnName=\"{c}\" runat=\"server\"/>  '\n",
    "    if c[-4:] == \"Date\":\n",
    "        dfld = f'<CB:DataField  DBColumnName=\"{c}\" Require=\"False\" DataType=\"System.DateTime\" NonDatePlaceholder=\"01/01/1900\" ImportColumnName=\"{c}\"  runat=\"server\"/>  '\n",
    "    # print(s) \n",
    "    print(dfld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for c in df.columns:\n",
    "    n = f'{normalize_var(c)}' \n",
    "    s = f',{n} NVARCHAR(MAX) NULL ' \n",
    "    # print(s)\n",
    "    dfld = f'<CB:DataField  DBColumnName=\"{n}\" Require=\"False\" ImportColumnName=\"{c}\" runat=\"server\"/>  '\n",
    "    if c[-4:] == \"Date\":\n",
    "        dfld = f'<CB:DataField  DBColumnName=\"{n}\" Require=\"False\" DataType=\"System.DateTime\" NonDatePlaceholder=\"01/01/1900\" ImportColumnName=\"{c}\"  runat=\"server\"/>  '\n",
    "    print(dfld )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\Tim\\Downloads\\fedramp.xlsx', sheet_name='Agency - CSP Table', header=1, usecols='B:Z' )  \n",
    "df.columns=[c.replace(' ' ,'') for c in df.columns] \n",
    "df\n",
    "# df.to_excel(r'C:\\Users\\Tim\\Downloads\\fedramp_admin_import.xlsx', sheet_name='Admin Import', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\timko\\Downloads\\TLP RED - FY25 HVA List - CyberScope Upload.xlsx', sheet_name='Export', header=0, usecols='A:Z' )   \n",
    "df['PK_HVA'] = df['HVA_ID'].apply(id)\n",
    "df['TierPK'] = df['Tier'].apply(tier)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "up = \"UPDATE fsma_HVAs SET Tier='t', AgencyRank='ar' WHERE PK_HVA = 'pk' ;\"\n",
    "sql=''\n",
    "for i, row in df[:].iterrows():\n",
    "    s=up.replace(\"'t'\", row[\"TierPK\"])\n",
    "    s=s.replace(\"'pk'\", row[\"PK_HVA\"])\n",
    "    s=s.replace(\"'ar'\", str(row[\"Rank within FHE\"]))\n",
    "    \n",
    "    sql=sql+s+'\\n'\n",
    "print( sql )\n",
    "\n",
    "\n",
    "with open(r'y:\\tkopp\\tscript.sql', 'w', encoding='UTF-8') as f: \n",
    "    f.write( f'\\n{sql}' ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = pd.read_csv(f'{ctx.get_dest()}fedramp.csv') \n",
    "df=normalizedf(fields)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = set(sql_todf(\"  SELECT Component FROM [Component List] WHERE IsActive=1 AND FK_PK_Component IS NULL  \", connstr)['Component']) \n",
    "ag = set(ag)\n",
    "ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df[:].iterrows():\n",
    "    s=f\",@{row['COLUMN_NAME']} {row['DATA_TYPE']}\"\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_fromTemplateColumn(path): \n",
    "    lst=[]\n",
    "    cols=[]\n",
    "    with open(path, 'r') as f:  \n",
    "        g=re.search(\"<Columns>(.*)<\\/Columns\", f.read() , flags=re.DOTALL)   \n",
    "        lst=g.groups(0)[0].split('<CB:CBGridTemplateColumn')[1:] \n",
    "        for l in lst: \n",
    "            un = re.search('UniqueName=\"(\\w+)\"\\s', l ).groups(0)[0] \n",
    "            ht = un\n",
    "            if 'HeaderText' in l:\n",
    "                try: ht = re.search('HeaderText=\"([A-Za-z\\s]*)\"', l ).groups(0)[0]  \n",
    "                except:  pass \n",
    "            cols.append({  'UniqueName': un ,'HeaderText':ht   })\n",
    "            \n",
    "    return pd.DataFrame(cols)\n",
    "df = df_fromTemplateColumn(r'C:\\dev\\CyberScope\\CyberScopeBranch\\CSwebdev\\code\\CyberScope\\BODSCuBA\\2024\\2024_A_SCuBATenantInventory_1.aspx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i,r in df.iterrows(): \n",
    "    un = r['UniqueName'] \n",
    "    ht = r['HeaderText'] \n",
    "    s = f'<CB:DataField  DBColumnName=\"{un.replace(\" \",\"\")}\" Require=\"False\" ImportColumnName=\"{ht}\" runat=\"server\"/>  '\n",
    "    if \"Date\" in un: \n",
    "        s = f'<CB:DataField  DBColumnName=\"{un.replace(\" \",\"\")}\" Require=\"False\" ImportColumnName=\"{ht}\"  runat=\"server\"/>  '\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in df.iterrows(): \n",
    "    DATA_TYPE=r[\"DATA_TYPE\"]\n",
    "    COLUMN_NAME=r[\"COLUMN_NAME\"]\n",
    "    HEADER=r[\"HEADER\"]\n",
    "    PK_PICKLISTTYPE=str(r[\"PK_PICKLISTTYPE\"] )\n",
    "    s=f'<CB:DataField DBColumnName=\"{COLUMN_NAME}\" ImportColumnName=\"{HEADER}\" SprocParamName=\"{COLUMN_NAME}\" runat=\"server\"/>' \n",
    "    s=f',{COLUMN_NAME} '\n",
    "    if PK_PICKLISTTYPE != '0': s=s.replace('runat',' PickListTypeID=\"'+ PK_PICKLISTTYPE +'\" runat')   \n",
    "    \n",
    "    e=f',{COLUMN_NAME} AS [{HEADER}] '\n",
    "    if PK_PICKLISTTYPE != '0': e=f', (SELECT DisplayValue FROM vwPICKLISTS WHERE PK_Picklist={COLUMN_NAME}) AS [{HEADER}]' \n",
    "    if 'Date' in COLUMN_NAME:\n",
    "        e=f\" , CASE WHEN {COLUMN_NAME} LIKE '%2000%' THEN 'NA' ELSE FORMAT({COLUMN_NAME}, 'MM/dd/yyyy') END AS [{HEADER}]\"\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, row in df[:].iterrows():\n",
    "    with open(ctx.get_tempalte_dir()+'GridTemplateColumn.aspx', 'r') as f: \n",
    "        s=f.read()  \n",
    "    DATA_TYPE=row['DATA_TYPE']\n",
    "    COLUMN_NAME=row['COLUMN_NAME']\n",
    "    HEADER=row['HEADER']\n",
    "    PK_PICKLISTTYPE=row['PK_PICKLISTTYPE']\n",
    "    s=s.replace('{COLUMN_NAME}', COLUMN_NAME)\n",
    "    if 'INT' in DATA_TYPE:  \n",
    "        s=s.replace('{Bind_COLUMN_NAME}', COLUMN_NAME+'_Display')\n",
    "        s=s.replace('<%-- --%>', f'<telerik:RadDropDownList ID=\"{COLUMN_NAME}\" DataValueField=\"YN\" runat=\"server\" />')  \n",
    "    else:\n",
    "        s=s.replace('{Bind_COLUMN_NAME}', COLUMN_NAME )\n",
    "        if 'Date' in COLUMN_NAME:  \n",
    "            # print(\"const \"+COLUMN_NAME+\" = new CBDatePicker({ id: $(`[id$=_\"+COLUMN_NAME+\"]`).prop('id'), allowNa: true  }); \")  \n",
    "            s=s.replace('<%-- --%>', f'<asp:HiddenField ID=\"{COLUMN_NAME}\" runat=\"server\" />') \n",
    "        else: \n",
    "            s=s.replace('<%-- --%>', f'<telerik:RadTextBox ID=\"{COLUMN_NAME}\" runat=\"server\" />') \n",
    "    #print(f\"[{COLUMN_NAME}] [NVARCHAR](4000) NULL,\")  \n",
    "    #print('{ field: \"'+COLUMN_NAME+'\", title: \"'+HEADER+'\" },')\n",
    "    print (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def get_gridcols(df,out=False):\n",
    "    ldf=df.to_dict(orient='records') \n",
    "    code,ddl,dv,sel,dtf=[],[],[],[],[]\n",
    "    with open(ctx.get_tempalte_dir()+'GridTemplateColumn.aspx', 'r') as f: \n",
    "        t=f.read() \n",
    "        \n",
    "        for d in ldf: \n",
    "            col=d['COLUMN_NAME'] \n",
    "            s=t.replace(\"{COLUMN_NAME}\",d['COLUMN_NAME'])  \n",
    "            if 'INT' in d['DATA_TYPE'].upper():\n",
    "                s=s.replace('{Bind_COLUMN_NAME}',f\"{d['COLUMN_NAME']}_Display\")\n",
    "                s=s.replace('<%-- --%>', f'<telerik:RadDropDownList ID=\"{col}\" DataValueField=\"YN\" runat=\"server\" />')\n",
    "                ddl.append(f'BindDDL(e, \"{col}\", \"{col}\", \"{col}\")')\n",
    "                sel.append(f',(SELECT DisplayValue FROM vwPICKLISTS WHERE PK_Picklist={col}) AS {col}') \n",
    "            else: \n",
    "                s=s.replace('{Bind_COLUMN_NAME}',f\"{d['COLUMN_NAME']}\")\n",
    "                s=s.replace('<%-- --%>', f'<telerik:RadTextBox ID=\"{col}\" runat=\"server\" />')\n",
    "                dv.append(f'DirectCast(e.Item.FindControl($\"{col}\"), RadTextBox).Text = drVal(\"{col}\").ToString()')\n",
    "                sel.append(f',{col}') \n",
    "            code.append(f'{s}')     \n",
    "    code='\\n'.join(code) \n",
    "    ddl='\\n'.join(ddl)\n",
    "    dv= '\\n'.join(dv)\n",
    "    sel= '\\n'.join(sel)[1:] \n",
    "    return {'code':code, 'ddl':ddl,'dv':dv,'sel':sel, 'dtf': dtf}\n",
    "  \n",
    " \n",
    "p = get_gridcols(df, out=False)\n",
    "p\n",
    "print ( p['code'] ) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = get_gridcols(df)\n",
    "print( sql['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql(df,out=False):\n",
    "    parms=[]\n",
    "    for i,r in df.iterrows():\n",
    "        s=f\"@{r['COLUMN_NAME']} {r['DATA_TYPE'].upper()}({r['CHARACTER_MAXIMUM_LENGTH']}) = NULL\"\n",
    "        if r['DATA_TYPE'].upper() == 'INT':\n",
    "            s=f\"@{r['COLUMN_NAME']} {r['DATA_TYPE'].upper()} = NULL\"  \n",
    "        parms.append(f',{s}')\n",
    "\n",
    "    into=', '.join([c for c in df['COLUMN_NAME'] if 'PK_' not in c])\n",
    "    vals=', @'.join([c for c in df['COLUMN_NAME'] if 'PK_' not in c]) \n",
    "    ins=f'\\n INSERT INTO @TABLE ({into}) \\n VALUES (@{vals})'\n",
    "\n",
    "    parms='\\n'.join(parms)[:] \n",
    "    update=', '.join([f'{c}=@{c}' for c in df['COLUMN_NAME'] if 'PK_' not in c ])  \n",
    "    ext=' AND ' + ' AND '.join([f'{c}=@{c}' for c in df['COLUMN_NAME'] if 'PK_' not in c ])\n",
    "\n",
    "    sel=[] \n",
    "    exp=[]\n",
    "    for i,r in df.iterrows():   \n",
    "        s=f\"\\n, {r['COLUMN_NAME']} \"\n",
    "        if r['DATA_TYPE'].upper() == 'INT':   \n",
    "            s=s+f\"\\n, (SELECT DisplayValue FROM vwPicklists WHERE PK_Picklist={r['COLUMN_NAME']}) AS [{r['COLUMN_NAME']}_Display]\" \n",
    "            exp.append(f\"\\n, (SELECT DisplayValue FROM vwPicklists WHERE PK_Picklist={r['COLUMN_NAME']}) AS [{r['HEADER']}]\")\n",
    "        elif r['DATA_TYPE'].upper() == 'DATETIME':\n",
    "            s=s+f\"\\n, FORMAT({r['COLUMN_NAME']}, 'MM/dd/yyyy') AS [{r['COLUMN_NAME']}_Display] \" \n",
    "            exp.append(f\"\\n, FORMAT({r['COLUMN_NAME']}, 'MM/dd/yyyy') AS [{r['HEADER']}]\") \n",
    "        else:\n",
    "            exp.append(f\"\\n, {r['COLUMN_NAME']} AS [{r['HEADER']}]\")\n",
    "        sel.append(''+s)\n",
    "    sel=''.join(sel)  \n",
    "    exp=''.join(exp)  \n",
    "    return {'parms':parms,'ins':ins, 'update':update, 'sel':sel, 'ext':ext, 'exp':exp  }\n",
    "\n",
    "\n",
    "# df = sql_todf(\"SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME='FEDRAMP_UPLOAD'\", ctx.connstr) \n",
    "# df = normalizedf(df) \n",
    "#  df.columns\n",
    "d=get_sql(df, out=False)\n",
    "print( d['ins'].replace(',','\\n,')  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a7c076192e1e16d3ee1a218e6831777c4d2e3a001a9a33f6decd6c7672cec63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
