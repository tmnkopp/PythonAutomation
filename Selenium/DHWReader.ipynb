{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re,  os, time, random \n",
    "from bs4 import BeautifulSoup  \n",
    "import pymongo , bson\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "sw=stopwords.words('english')\n",
    "import pandas as pd \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn) \n",
    "db = client.dhwy\n",
    "collection = db.posts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"--start-minimized\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=ChromeDriverManager().install() ,chrome_options=options) \n",
    "base = 'https://dallashwy.com'\n",
    "driver.get(f\"{base}/index.php?forums/politics.8/\")   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup(driver.page_source, 'html.parser')\n",
    "base = 'https://dallashwy.com'\n",
    "driver.get(f\"{base}/index.php?forums/politics.8/\")  \n",
    "pages = 0\n",
    "while True:  \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')  \n",
    "    try:\n",
    "        get_topics( driver.current_url  )\n",
    "    except e:\n",
    "        print(e)\n",
    "            \n",
    "    nxt = soup.select('link[rel=\"next\"]')  \n",
    "    if len(nxt) > 0 and pages <= 250: \n",
    "        driver.get(f\"{base}{nxt[0]['href']}\")  \n",
    "        pages = pages + 1\n",
    "    else: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(url):\n",
    "    driver.get(f\"{url}\")\n",
    "    topics = driver.find_elements_by_css_selector('.structItem--thread .structItem-title a') \n",
    "    hrefs = []\n",
    "    for topic in topics[:20]:  \n",
    "        hrefs.append(topic.get_attribute('href'))\n",
    "    for href in hrefs:  \n",
    "        driver.get(f\"{href}\") \n",
    "        while True:   \n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            print_thread(driver)\n",
    "            nxt = soup.select('link[rel=\"next\"]')  \n",
    "            if len(nxt) > 0:   \n",
    "                driver.get(f\"{base}{nxt[0]['href']}\") \n",
    "                try:\n",
    "                    print_thread(driver)\n",
    "                except e:\n",
    "                    print(e)\n",
    "            else: \n",
    "                break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_thread(driver): \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    arts = soup.select('article.message')\n",
    "    i = 0\n",
    "    d={}\n",
    "    for a in arts:  \n",
    "        d['key']=a['id']\n",
    "        d['author']=a['data-author']\n",
    "        d['title']=soup.select('title')[0].get_text() \n",
    "        d['url']=base+a.select('header a')[0]['href']\n",
    "        ele = a.select('time.u-dt') \n",
    "        if len(ele) > 0: \n",
    "            d['date']=ele[0].get_text() \n",
    "        ele = a.select('.message-body .bbWrapper') \n",
    "        if len(ele) > 0:  \n",
    "            d['mess']=ele[0].get_text()\n",
    "        ele = a.select('a.link--external') \n",
    "        if len(ele) > 0:  \n",
    "            d['mess']=d['mess']+ele[0]['href']\n",
    "        ele = a.select('.bbImageWrapper') \n",
    "        if len(ele) > 0:  \n",
    "            d['mess']=d['mess']+ele[0]['data-src']\n",
    "        # print(d)\n",
    "        #collection.delete_one( d )\n",
    "        #collection.insert_one( d ) \n",
    "        collection.update( { 'key':  d['key']  }, d, True   ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(collection.find()))\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dff = df.loc[df.author.str.contains('Far West')] \n",
    "#dff = df.loc[df.mess.str.contains('vacc')] \n",
    "for i,r, in dff.iterrows():\n",
    "    print( r['author'] + ' ' +  r['date']+ ' ' +  r['title'])\n",
    "    print(r['mess'] )\n",
    "    print(r['url'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = driver.find_elements_by_css_selector('.pageNavWrapper')\n",
    "for p in pages:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in eles:\n",
    "    ele=e.find_element_by_css_selector('.structItem-title a')\n",
    "    print(ele.get_attribute('id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elms = driver.find_elements(By.XPATH, '//ul[contains(@id, \"search-results\")]//h3/a') \n",
    "hrefs = [e.get_attribute('href') for e in elms]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for url in hrefs[:12]:\n",
    "    driver.execute_script( 'window.open();')   \n",
    "    driver.switch_to_window(driver.window_handles[ len(driver.window_handles)-1])\n",
    "    driver.get(url)\n",
    "driver.window_handles[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ecbac8c226a054463cc020fa45cbf820e7d49ac7199c163081ea57c79aed41e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
