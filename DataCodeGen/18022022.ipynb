{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, subprocess, pyodbc \n",
    "import numpy as np # linear algebra \n",
    "from sqlalchemy import func, create_engine\n",
    "from config import connstr\n",
    "import pandas as pd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf = pd.read_csv('ldf.csv').loc[:,['col','icn']]\n",
    "ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(connstr) \n",
    "def get_df(query):\n",
    "    conn = engine.connect() \n",
    "    df = pd.read_sql(query,con=conn) \n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_split(s):\n",
    "    s = s + '000'\n",
    "    s = re.sub('[^\\d]', '', s)  \n",
    "    return s[:4] \n",
    "#print( id_split('5.1-4') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_num(s):\n",
    "    if s == '':\n",
    "        return 0\n",
    "    s = s.strip().lower().replace(' ', '')\n",
    "    l = ['a','b','c','d','e','f','g','h']\n",
    "    d = [.100, 1, 100, 10000]\n",
    "    v = [0,0,0,0]\n",
    "    for i, c in enumerate(l):\n",
    "        s = s.replace(c,f'{i}') \n",
    "    l = s.split('.')\n",
    "    for i, c in enumerate(l):\n",
    "        v[i] =  int(c) / d[i] \n",
    "    return sum(v)  \n",
    "print(id_num('1.1.1')) \n",
    "print(id_num('1.1.10.1')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizedf(df):\n",
    "    df.drop( columns=[c for c in df.columns if '__' in c ] , inplace=True )   \n",
    "    cols = list(df)   \n",
    "    df['DATA_TYPE']=df['DATA_TYPE'].str.upper() \n",
    "    df['PK_PickListType']=df['PK_PickListType'].fillna(0).astype(int)\n",
    "    df['CHARACTER_MAXIMUM_LENGTH']=df['CHARACTER_MAXIMUM_LENGTH'].fillna(0).astype(int)\n",
    "    df[cols] = df[cols].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = f\"\"\" \\\n",
    "SELECT * FROM INFORMATION_SCHEMA.COLUMNS \n",
    "LEFT JOIN PickListTypes ON UsageField=COLUMN_NAME\n",
    "WHERE TABLE_NAME = 'PQCInventory' \n",
    "\"\"\"  \n",
    "df  = get_df(query)  \n",
    "df = normalizedf(df)\n",
    "df = pd.merge(df,ldf, left_on='COLUMN_NAME', right_on='col')\n",
    "df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "txt=[]   \n",
    "for i,r in df.iterrows():\n",
    "    plt=''\n",
    "    PK_PickListType=r['PK_PickListType']\n",
    "    COLUMN_NAME=r['COLUMN_NAME']\n",
    "    DATA_TYPE=r['DATA_TYPE']\n",
    "    CHARACTER_MAXIMUM_LENGTH=r['CHARACTER_MAXIMUM_LENGTH']\n",
    "    if PK_PickListType != '0':\n",
    "        plt=f' PK_PickListType=\"{PK_PickListType}\" '\n",
    "    s=f'<CB:DataField DBColumnName=\"{COLUMN_NAME}\" ImportColumnName=\"{COLUMN_NAME}\" {plt} runat=\"server\"/>'\n",
    " \n",
    "    txt.append(f'{s}')\n",
    "txt='\\n'.join(txt) \n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sql=[]   \n",
    "for i,r in df.iterrows():\n",
    "    s=f\"@{r['COLUMN_NAME']} {r['DATA_TYPE'].upper()}({r['CHARACTER_MAXIMUM_LENGTH']}) = NULL\"\n",
    "    if r['DATA_TYPE'] == 'INT':\n",
    "        s=f\"@{r['COLUMN_NAME']} {r['DATA_TYPE'].upper()} = NULL\" \n",
    "    sql.append(f',{s}')\n",
    "sql='\\n'.join(sql)[1:]\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfh = pd.read_excel(r'C:\\Users\\Tim\\Documents\\1802\\HVA\\HVA1.xlsx', sheet_name='1') \n",
    "dfh = normalizedf(dfh) \n",
    "dfh['QuestionText'] = ''\n",
    "dfh[0:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(r'C:\\Users\\Tim\\Documents\\1802\\HVA\\HVA1.xlsx', sheet_name='ALL') \n",
    "df1 = normalizedf(df1) \n",
    "df1[1:2]  # .loc[ df1['IDTEXT'].str.contains('5.') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ppl = pd.read_excel(r'C:\\Users\\Tim\\Documents\\1802\\HVA\\HVA1.xlsx', sheet_name='PurposePickList' )\n",
    "l=[]\n",
    "c=0\n",
    "for i,r in ppl.iterrows():\n",
    "    if i % 2==1: \n",
    "        continue\n",
    "    c=c+1\n",
    "    IDTEXT = f\"1.1.{ c }\"\n",
    "    QuestionText = f\"{ r['DisplayValue'] }\"\n",
    "    l.append( {'IDTEXT':f'{IDTEXT}', 'QuestionText': f\"If {QuestionText}, describe:\"})\n",
    "ppl = pd.DataFrame(l)  \n",
    "ppl.to_csv(r'C:\\Users\\Tim\\Documents\\1802\\HVA\\ppl.csv', index=False)  \n",
    "ppl[0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = pd.read_csv(r'C:\\Users\\Tim\\Documents\\1802\\HVA\\HVAPurpose.csv' )\n",
    "dfp['IDTEXT'] = dfp['IDTEXT'].apply(lambda s : s.replace('.a','.1'))\n",
    "dfp['IDTEXT'] = dfp['IDTEXT'].apply(lambda s : s.replace('.b','.2'))\n",
    "dfp = normalizedf(dfp)  \n",
    "dfp[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = pd.merge(df1, dfp, how='outer', on=['IDTEXT', 'QuestionText'], suffixes=(None, '__')) \n",
    "dfm = normalizedf(dfm)\n",
    "dfm.to_csv(r'C:\\Users\\Tim\\Documents\\1802\\HVA\\dfm.csv', index=False)  \n",
    "dfm[0:2]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = dfm\n",
    "dfa = normalizedf(dfa) \n",
    "for i,r in dfa.iterrows():\n",
    "    v=dfa.loc[i, 'QuestionText']\n",
    "    if v=='':\n",
    "        dfa.loc[i, 'QuestionText']=dfa.loc[i, 'QuestionText_']\n",
    "dfa.to_csv(r'C:\\Users\\Tim\\Documents\\1802\\HVA\\dfa.csv', index=False)   \n",
    "dfa['QuestionText'].fillna('')\n",
    "dfa[0:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dff = pd.merge(dfa, dfq, how='left', on='IDTEXT', suffixes=('', '_y')) \n",
    "dff['FK_QuestionType'].fillna('9', inplace=True)\n",
    "dff['FK_PickList'].fillna('NULL', inplace=True)\n",
    "dff['FK_PickListType'].fillna('NULL', inplace=True)\n",
    "dff['WarningQuestion'].fillna('NULL', inplace=True)\n",
    "dff['PK_ExternalLink'].fillna('NULL', inplace=True)\n",
    "dff['PK_Question']=dff['QPK']\n",
    "dff['FK_InputType'].fillna('NULL', inplace=True) \n",
    "dff['help_text'].fillna('NULL', inplace=True) \n",
    "dff = dff.fillna('NULL')\n",
    "dff  = dff.replace('None','NULL')\n",
    "dff.to_csv(r'C:\\Users\\Tim\\Documents\\1802\\HVA\\dfa.csv', index=False)   \n",
    "dff[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"  SELECT TOP 1 \n",
    "    PK_Question, FormName, FK_QuestionGroup,sortpos,identifier_text, FK_QuestionType\n",
    "    , FK_InputType, FK_PickListType, WarningQuestion, ExternalLinkType, QuestionText, help_text \n",
    "    FROM fsma_Questions \n",
    "    \"\"\"  \n",
    "df_qmeta = get_df(query) \n",
    "cols = ','.join(df_qmeta.columns)\n",
    "INS = f'INSERT INTO fsma_Questions ({cols}) VALUES '\n",
    "print(INS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = get_df(\"\"\"\n",
    "SELECT PK_Question QPK\n",
    "  , CONVERT(NVARCHAR(9), FK_QuestionType) + '' FK_QuestionType\n",
    "  , CONVERT(NVARCHAR(9), FK_PickListType) + '' FK_PickListType\n",
    "  , QTEXT As QuestionText\n",
    "  , help_text\n",
    "  , IdText as IDTEXT \n",
    "  FROM vwQuestions WHERE QGROUP=2433\n",
    "  ORDER BY SortPos ASC\n",
    "\"\"\") \n",
    "dff=dff.fillna('~')\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\" \n",
    "for i, r in dff[:].iterrows(): \n",
    "    s = \"(@QID, @FormName, @PK_QGroup, @SORD, N'@IDTEXT', @QTYPE, 1, @PKTYPE, 0, NULL, N'@QTEXT','@HTEXT'),\"\n",
    "    s = s.replace('@QID',  str(r['QPK']))\n",
    "    s = s.replace('@SORD', str(i+1)) \n",
    "    s = s.replace('@QTYPE', r['FK_QuestionType'])\n",
    "    s = s.replace('@PKTYPE', r['FK_PickListType'])\n",
    "    s = s.replace('@IDTEXT', r['IDTEXT']) \n",
    "    s = s.replace('@QTEXT', r['QuestionText'].replace('\\'', '`').replace('\\ufffd', ''))  \n",
    "    s = s.replace('@HTEXT', r['help_text'])  \n",
    "    sql = sql + s + '\\n'\n",
    "sql = sql.replace(\"'~')\", \"NULL)\")    \n",
    "# sql = sql.replace(\"N'NULL'\", \"N''\")   \n",
    "sql = sql.replace(\"~,\", \"NULL,\")  \n",
    "# sql = f'{INS}\\n {sql}\\n' \n",
    "print( sql )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fr'C:\\Users\\Tim\\Documents\\1802\\HVA\\update.sql', 'w') as f:\n",
    "    f.write(sql)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "df = pd.read_excel(r'C:\\Users\\Tim\\Documents\\1802\\HVA\\HVA1.xlsx', sheet_name='PurposePickList').fillna('NULL') \n",
    "cols = list(df) # Creates list of all column headers\n",
    "df[cols] = df[cols].astype(str)\n",
    "df['DisplayCode'] =  df['DisplayValue'].apply(lambda s: re.sub('[^A-Z0-9]','',s.upper()))\n",
    "df['DisplayCode'] =  df['DisplayCode'].apply(lambda s: re.sub('[AEIOURST]','',s)[:8])\n",
    "s =''\n",
    "for i,r, in df.iterrows():\n",
    "    PK_PickList=r['PK_PickList']\n",
    "    DisplayCode=r['DisplayCode']\n",
    "    DisplayValue=r['DisplayValue'] \n",
    "    if DisplayValue=='Other':\n",
    "        DisplayCode='OTH'\n",
    "    s = s + f\"({PK_PickList},@PKT, N'{DisplayCode}',N'{DisplayValue}',{i}, GETDATE(), 1),\\n\"\n",
    "\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\" \\\n",
    "    SELECT TOP 5000 \n",
    "      IDTEXT AS IDTEXT \n",
    "    , PK_Question \n",
    "    FROM vwQuestions WHERE PK_FORM LIKE '2022-A-HVA'  \n",
    "\"\"\"  \n",
    "dfdep = get_df(query)  \n",
    "# dfdep.to_csv(r'C:\\Users\\Tim\\Documents\\1802\\HVA\\dfdep.csv', index=False)  \n",
    "dfdep[:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INS = f\"\"\"  INSERT INTO [fsma_QuestionDependencies] \n",
    "(FK_Question, FK_Question_Master, Question_Master_CodeValue_ToMakeRequired) VALUES \n",
    "    \"\"\"  \n",
    "sql = \"\"   \n",
    "for i, r in dfdep[:].iterrows(): \n",
    "    mast = 28211\n",
    "    s = f\"({r['PK_Question']}, {mast}, 'Y') ,\"     \n",
    "    sql = sql + s + '\\n' \n",
    "sql = f'{INS}\\n {sql}\\n' \n",
    "# print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a7c076192e1e16d3ee1a218e6831777c4d2e3a001a9a33f6decd6c7672cec63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
